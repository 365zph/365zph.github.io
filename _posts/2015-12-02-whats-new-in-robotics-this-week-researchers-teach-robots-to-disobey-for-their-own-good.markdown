---
author: viviworld
comments: true
date: 2015-12-02 10:29:17+00:00
excerpt: 随着人类和机器人开始近距离地工作、以及机器人走入我们的家庭，传统关系衍生出了很多问题。机器人每次都不折不扣地执行人类指令，就成为糟糕的考虑，举个最明显的例子，当服从人类指令时，可能让机器人潜在地破坏它自己或其它财产。
layout: post
link: http://www.labazhou.net/2015/12/whats-new-in-robotics-this-week-researchers-teach-robots-to-disobey-for-their-own-good/
slug: whats-new-in-robotics-this-week-researchers-teach-robots-to-disobey-for-their-own-good
title: 研究人员教机器人如何更好地拒绝人类命令
wordpress_id: 2845
categories:
- 杂项
- 网络
tags:
- 机器人
---


	
  * 原文地址（original source）：[http://robohub.org/whats-new-in-robotics-this-week-researchers-teach-robots-to-disobey-for-their-own-good/](http://robohub.org/whats-new-in-robotics-this-week-researchers-teach-robots-to-disobey-for-their-own-good/)

	
  * _by Emmet Cole, The Robot Report_


_译者注：由于本文是节选，原始文章可参考：[**IEEE Spectrum**](http://spectrum.ieee.org/automaton/robotics/artificial-intelligence/researchers-teaching-robots-how-to-best-reject-orders-from-humans)_



* * *



Youtube 视频地址：[https://www.youtube.com/watch?v=SkAAl7ERZPo](https://www.youtube.com/watch?v=SkAAl7ERZPo)

机器人常常被视作纯粹的奴隶，设计之初就是为了不折不扣地服从人类的命令。「robot（机械般工作的人）」就是从捷克语[派生而来](http://www.etymonline.com/index.php?term=robot)的，意思是「奴役」。

在人类安全距离之外运作的巨型行业机器人、以及工厂内的其它装备都是极好的例子，它们代表了传统的「人类君主 - 机器人奴隶」的关系。这类机器人以计算机代码的形式接收严格的指令，然后不折不扣地执行。

但是，随着人类和机器人开始[近距离地](http://blog.robotiq.com/what-does-collaborative-robot-mean)工作、以及机器人走入我们的家庭，传统关系衍生出了很多问题。

首先，机器人运作的环境相较于简单的「笼子里的机器人」，正变得更为复杂。

其次，很多家用机器人的设计是基于通过声音接收指令、而非计算机代码，这增加了可能发生的潜在灾祸的范围。

鉴于此，机器人每次都不折不扣地执行人类指令，就成为糟糕的考虑，举个最明显的例子，当服从人类指令时，可能让机器人潜在地破坏它自己或其它财产。

让我们坦然面对吧，家用机器人可能要接收各种命令，还附加了各种常识和美好意图：

「我把手机丢在游泳池了，你能帮我取出来吗？」

这种指令仅仅适用于防水机器人，但是我们无法阻止某些人发出这种指令，要么未经思考指令的合理性、要么只是看看接下来会发生什么。

简言之，机器人需要对其所处环境具备足够的智能和意识，这样才能区分合理指令和愚蠢指令。

这就是[塔夫斯大学](http://hrilab.tufts.edu/)（美国一大学名）一组研究人员希望完成的结果，他们在开发一种机制，让机器人拒绝接收人类的命令，只是要有充足的理由：


<blockquote>「现在，我们探讨一下所有这些因素在实践中的运作过程，即人类和机器人的真实交互。总体目标，除了教机器人什么时候应该（以及不应该）服从命令，还要提供一种框架，让机器人能够有效地沟通它拒绝某条命令的理由。这很重要，因为它允许人类提供额外的指令，或许能够满足某种把引起错误摆在首位的[适切条件](https://en.wikipedia.org/wiki/Felicity_conditions)。【注1】

当人类命令可能导致伤害机器人本身时，机器人会无视命令，因此就颠倒了[机器人第二定律和第三定律](https://en.wikipedia.org/wiki/Laws_of_robotics#Isaac_Asimov.27s_.22Three_Laws_of_Robotics.22)【注2】的顺序。

我们正在设定能够毁灭人类的危险范例吗？是的，可能吧。但是，期望机器人完全服从它们接触到的所有人类的定律，也是不现实的：如果我们尽量用计算机和软件实现，就会导致大量的、带有毁灭性的混乱，并且机器人学的现在和未来就没有什么不同。」</blockquote>


在[这里](http://hrilab.tufts.edu/publications/briggsscheutz15aaaifs.pdf)阅读全文。

除了简单的保护自己安全，可能还存在其他机器人不服从的可能性。

或许，只有我这样认为，不过，我觉得我会非常喜欢有这么一个家用[机器人](http://www.labazhou.net/2015/08/what-is-the-definition-of-a-robot/)，当安全因素出现时，它不但能够质疑我的指令，而且如果没有什么特别理由的话，能够定期地完全拒绝我。

为什么？想想大脑训练设备、而非机器人管家。这样一种机器人将有希望让我保持警醒，我们的关系也不会递减到检查员 Clouseau 与 Cato 的那种水平：

Youtube 视频地址：[https://www.youtube.com/watch?time_continue=50&v=S2l5Yt6LBfo](https://www.youtube.com/watch?time_continue=50&v=S2l5Yt6LBfo)


### 注释

* 注1：转喻连接的力度与语用推理：我们认为言语行为和其适切条件（felicity conditions）都可由言语行为脚本来描写。但需要强调指出的是，言语行为脚本的部分转喻整个脚本的力度是有差异的。[http://www.daixie.org.cn/wenshi/yuyanxue/40396.html](http://www.daixie.org.cn/wenshi/yuyanxue/40396.html) 
* 注2：机器人三定律（Three Laws of Robotics）是科幻小说家艾萨克·阿西莫夫（Isaac Asimov）在他的机器人相关作品和其他机器人相关小说中为机器人设定的行为准则，是阿西莫夫除“心理史学”（Psychohistory）外另一个著名的虚构学说。[https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%89%E5%AE%9A%E5%BE%8B](https://zh.wikipedia.org/wiki/%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%B8%89%E5%AE%9A%E5%BE%8B) 
